{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "#sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Oliver\\\\Documents\\\\Academic\\\\Applied data analysis and machine learning\\\\Projects\\\\FYS-STK4155-project2\\\\notebooks', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python39.zip', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\DLLs', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\lib', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39', '', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\lib\\\\site-packages', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\lib\\\\site-packages\\\\win32', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\lib\\\\site-packages\\\\Pythonwin', 'c:\\\\users\\\\oliver\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Oliver\\\\.ipython', '../', '../src/']\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../')\n",
    "sys.path.append('../src/')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.create_dataset import *\n",
    "from src.visualization.visualize import *\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so data looks fairly simple, it's a design matrix with 40 features and 569 samples. We simply input it to the model like normal. So the inputs are continuous, but the target data, i.e the z data are 0's and 1's. So we're esentially creating a linear function that produces a result which is continuous and is then fed into sigmoid, which then classifies, or simply gives probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, z_train, z_test = train_test_split(cancer.data,cancer.target)\n",
    "z_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, z_train, z_test = train_test_split(cancer.data,cancer.target)\n",
    "Xscaler = StandardScaler().fit(X_train)\n",
    "#zscaler = StandardScaler().fit(z_train)\n",
    "\n",
    "X_train = Xscaler.transform(X_train)\n",
    "X_test = Xscaler.transform(X_test)\n",
    "#z_train = zscaler.transform(z_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n",
      "(383, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.modelling.nn.NeuralNetwork at 0x1d631fed970>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.modelling.nn import NeuralNetwork\n",
    "nn = NeuralNetwork(hidden_activation = 'relu',output_activation = 'sigmoid', loss_func = 'cross_entropy',\n",
    "                   momentum = 0.5,w_init='glorot',batch_size = 32,n_epochs = 1000,val_fraction=0.1)\n",
    "nn.fit(X_train,z_train.reshape(-1,1))\n",
    "#nn.predict(cancer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d6322de400>]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.val_loss)\n",
    "#plt.plot(nn.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.89962572574761"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nn.layers[0].weights.ravel()@nn.layers[0].weights.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So overflow when just feeding data un standardized directly into my network. What about keras or sklearn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "init_b = tf.keras.initializers.Constant(value=0.001)\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(100, kernel_initializer=initializer,bias_initializer= init_b, input_shape=(30,)))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(50, kernel_initializer=initializer,bias_initializer= init_b))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(1, kernel_initializer=initializer,bias_initializer= init_b))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=0.01,momentum=0.5)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,z_train,batch_size = 32, epochs=1000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(cancer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(index=2).get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_sk = MLPClassifier(max_iter = 1000, hidden_layer_sizes=(100,50),\n",
    "                     activation = 'relu',solver='sgd',\n",
    "                     learning_rate_init=0.01,batch_size = 32,momentum= 0.5,alpha=0.0,tol=0)\n",
    "nn_sk.fit(X_train,z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nn_sk.predict_proba(X_train))\n",
    "print('\\n')\n",
    "print(nn_sk.coefs_[-1].shape)\n",
    "print(nn_sk.classes_)\n",
    "print(nn_sk.get_params())\n",
    "nn_sk.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y = to_categorical(cancer.target)\n",
    "y2 = OneHotEncoder().fit_transform(cancer.target.reshape(-1,1))\n",
    "print(y.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cancer.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y3 = lb.fit_transform(cancer.target)\n",
    "y3[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what might be the case is simply that sklearn and keras implements methods to avoid numerical instabilities so that computation can continue. With  inf values here and there an activation with sigmoid will simply result in 1, or minus inf will result in 0. So perhaps somehow the probability outputted, not being 1 btw, has something to do either with the distribution of the data set, or that it magically somehow converges to 0.62 something. Perhaps something to do with e?\n",
    "\n",
    "So the weights of sklearn and keras are not infinite, they are something. But perhaps those are the weights that reached the limit of maximum number in terms of computational stability?\n",
    "\n",
    "Either way, turned out that standardizing the data helped majorly in avoiding exploding gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n",
      "(383, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.modelling.logreg.SGD_logreg at 0x1d632108550>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.modelling.logreg import SGD_logreg\n",
    "\n",
    "logreg = SGD_logreg(n_epochs=10000)\n",
    "logreg.fit(X_train,z_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train,z_train.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah so if SGD_logreg inherits from SGD_linreg that inherits from SGD_optimizer, it does indeed get the fit function, however it inherits the fit function SGD_linreg inherited, which uses SGD_linregs predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d632289250>]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(logreg.scores)\n",
    "plt.plot(logreg.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when pumping up n epochs, we see that the model does improve on test data, however stagnates at 0.96, and doesn't ever decrease. I guess it's hard to overfit now, because we have the features that we have and model complexity can't increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965034965034965"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test,z_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05235891],\n",
       "       [-0.01117482],\n",
       "       [-0.04907666],\n",
       "       [ 0.05323615],\n",
       "       [-0.02788537],\n",
       "       [ 0.13091652],\n",
       "       [-0.09944011],\n",
       "       [-0.00267761],\n",
       "       [ 0.01176267],\n",
       "       [-0.01108023],\n",
       "       [-0.02716792],\n",
       "       [ 0.00913157],\n",
       "       [ 0.11177889],\n",
       "       [-0.19197075],\n",
       "       [ 0.02090135],\n",
       "       [-0.02746825],\n",
       "       [ 0.06040906],\n",
       "       [-0.09146193],\n",
       "       [ 0.01738799],\n",
       "       [ 0.04251909],\n",
       "       [-0.10929564],\n",
       "       [-0.01323301],\n",
       "       [-0.04853388],\n",
       "       [ 0.0517787 ],\n",
       "       [-0.00571401],\n",
       "       [-0.03386452],\n",
       "       [-0.00030942],\n",
       "       [ 0.03188995],\n",
       "       [-0.02846331],\n",
       "       [-0.0320937 ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 30)\n",
      "(426, 30)\n",
      "(143,)\n",
      "(426,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\oliver\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#X_train, X_test, z_train, z_test = train_test_split(cancer.data,cancer.target,random_state=0)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(z_test.shape)\n",
    "print(z_train.shape)\n",
    "logreg_sk = LogisticRegression(solver='lbfgs')\n",
    "logreg_sk.fit(X_train,z_train)\n",
    "logreg_sk.score(X_test,z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40350877192982454"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok nice, so all methods seems to be working. A question is now, where do I go from here? Perhaps a train test result graph during training is useful? Unclear if that is normal. Though should be able to see if I reach a region of overfit at least. Several ways to do that. One can measure loss of a validation and train set during training, hm, or that's gonna be rather slow.\n",
    "\n",
    "So how to do overfit analysis? So one usually start with lr and lambda tuning, and then move on to other parameters. So how to see if num epochs gets too much? I guess I should have early stopping implemente. Because if I first tune lr and lmb without regards for overfitting then if I change n_epochs, the lr does perhaps not give a good answer anymore. Perhaps by implementing early stopping one would get the best 'test score' on every lr and lmb one tries. Although, I theory you would like the cost function to converge to a good solution, meaning plentiful epochs and still no overfit. So perhaps better aim many epochs, and then continuou search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I capture loss during training I can plot the graph and see how many epochs it took to somewhat converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1, -2])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.asarray([1,2,3])\n",
    "b = np.asarray([0.5,0.5,0.5])\n",
    "(1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
